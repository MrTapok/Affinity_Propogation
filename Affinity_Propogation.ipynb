{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сработало\n"
     ]
    }
   ],
   "source": [
    "edges = np.loadtxt('Gowalla_edges.txt',dtype=int)\n",
    "\n",
    "users = np.unique(edges)\n",
    "n = len(users)\n",
    "ed = len(edges)\n",
    "connections = []\n",
    "s_data = np.ones(ed, dtype=int)\n",
    "\n",
    "for i in range(0, ed):\n",
    "    connections.append((edges[i][0], edges[i][1]))\n",
    "    \n",
    "for i in range(0, n):\n",
    "    connections.append((i, i))\n",
    "    \n",
    "print(\"Сработало\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_propagation(s_data, connections, iterations_number, s_s, t_p):\n",
    "    \n",
    "    s_matrix = np.append(s_data, np.repeat(s_s, n))\n",
    "    r_matrix = np.zeros(s_matrix.shape[0], dtype=int)\n",
    "    a_matrix = np.copy(r_matrix)\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for j in range(0, iterations_number):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        print(\"Итерация #\" + str(j+1))\n",
    "        \n",
    "        #ответственность\n",
    "        \n",
    "        sum_temp = s_matrix + a_matrix\n",
    "        \n",
    "        print(a_matrix)\n",
    "        print(r_matrix)\n",
    "        \n",
    "        max_1 = np.zeros(n)\n",
    "        max_1.fill(-np.inf)     \n",
    "        max_2 = np.copy(max_1)\n",
    "        \n",
    "        max_p = np.zeros(n)\n",
    "        max_p.fill(np.inf)\n",
    "\n",
    "        for i, pair in enumerate(connections):\n",
    "            \n",
    "            if max_1[pair[0]] < sum_temp[i]:\n",
    "                max_2[pair[0]] = max_1[pair[0]]\n",
    "                max_1[pair[0]] = sum_temp[i]\n",
    "                max_p[pair[0]] = pair[1]\n",
    "            else:\n",
    "                if max_2[pair[0]] < sum_temp[i]:\n",
    "                    max_2[pair[0]] = sum_temp[i]\n",
    "        \n",
    "        new_r_matrix = s_matrix.copy()\n",
    "        \n",
    "        for i, pair in enumerate(connections):\n",
    "            if max_p[pair[0]] == pair[1]:\n",
    "                new_r_matrix[i] -= max_2[pair[0]]\n",
    "            else:\n",
    "                new_r_matrix[i] -= max_1[pair[0]]\n",
    "                \n",
    "        r_matrix = np.copy(new_r_matrix)\n",
    "        \n",
    "        sum_temp = []\n",
    "                \n",
    "        #доступность\n",
    "        \n",
    "        r_matrix_copy = r_matrix.copy()\n",
    "        \n",
    "        for i in range(0, ed):\n",
    "            if r_matrix_copy[i] < 0:\n",
    "                r_matrix_copy[i] = 0\n",
    "        \n",
    "        positive_r = np.repeat(0, n)\n",
    "    \n",
    "        for i, pair in enumerate(connections):\n",
    "            positive_r[pair[1]] += r_matrix_copy[i]\n",
    "        for i, pair in enumerate(connections):\n",
    "            a_matrix[i] = positive_r[pair[1]] - r_matrix_copy[i]\n",
    "        for i in range(0, len(edges)):\n",
    "            a_matrix[i] = np.min([0, a_matrix[i]])\n",
    "        \n",
    "        stop = time.time()\n",
    "        print(stop - start)\n",
    "    \n",
    "    #get cluster leaders\n",
    "\n",
    "    temp = np.zeros(n)\n",
    "    temp.fill(-np.inf)\n",
    "    \n",
    "    sum_temp = r_matrix + a_matrix\n",
    "\n",
    "    for i, pair in enumerate(connections):\n",
    "        if sum_temp[i] > temp[pair[0]]:\n",
    "            temp[pair[0]] = sum_temp[i]\n",
    "            result[pair[0]] = pair[1]\n",
    "            \n",
    "    for i in range(t_p):        \n",
    "        for a in result.keys(): \n",
    "            b = result[a] \n",
    "            if result[b] != b: \n",
    "                с = result[b] \n",
    "                result[a] = с \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp(data, pred_data, k):\n",
    "    try:\n",
    "        data = set(data[:k])\n",
    "    except:\n",
    "        data = set(data)\n",
    "    pred_data = set(pred_data)\n",
    "    return len(data.intersection(pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_number = 10\n",
    "s_s = -2\n",
    "t_p = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация #1\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "21.85358500480652\n",
      "Итерация #2\n",
      "[0 0 0 ... 0 0 0]\n",
      "[ 0  0  0 ... -3 -3 -3]\n",
      "21.890467643737793\n",
      "Итерация #3\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-3 -3 -3 ... -3  0  0]\n",
      "21.044742822647095\n",
      "Итерация #4\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-42 -42 -42 ...  -3  -3  -3]\n",
      "21.068674564361572\n",
      "Итерация #5\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-12 -12 -12 ...  -3   0   0]\n",
      "23.66075348854065\n",
      "Итерация #6\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-33 -33 -33 ...  -3  -3   0]\n",
      "21.11953592300415\n",
      "Итерация #7\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-18 -18 -18 ...  -3   0   0]\n",
      "24.048709630966187\n",
      "Итерация #8\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-30 -30 -30 ...  -3  -3   0]\n",
      "21.275128602981567\n",
      "Итерация #9\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-18 -18 -18 ...  -3   0   0]\n",
      "21.179352521896362\n",
      "Итерация #10\n",
      "[0 0 0 ... 0 0 0]\n",
      "[-30 -30 -30 ...  -3  -3   0]\n",
      "20.628878116607666\n",
      "Сработало\n",
      "Количество кластеров: 24801\n"
     ]
    }
   ],
   "source": [
    "result = affinity_propagation(s_data, connections, iterations_number, s_s, t_p)\n",
    "print(\"Сработало\")\n",
    "clusters = sorted(list(set(result.values())))\n",
    "print(\"Количество кластеров:\", len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сработало\n"
     ]
    }
   ],
   "source": [
    "clusters=(list(result.values()))\n",
    "cluster_sizes = {}\n",
    "for i in result.values():\n",
    "    if i not in cluster_sizes:\n",
    "        cluster_sizes[i] = 1\n",
    "    else:\n",
    "        cluster_sizes[i] += 1\n",
    "print(\"Сработало\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сработало\n"
     ]
    }
   ],
   "source": [
    "checkins_data = pd.read_csv(\"Gowalla_totalCheckins.txt\", sep=\"\t\", header=None)[[0, 4]]\n",
    "checkins_data.columns = [\"user_id\", \"location_id\"]\n",
    "\n",
    "temp = sorted(list(result.values()))\n",
    "\n",
    "clusters_data = pd.DataFrame(temp)\n",
    "clusters_data = clusters_data.reset_index()\n",
    "clusters_data.columns = [\"user_id\", \"cluster_id\"]\n",
    "\n",
    "all_data = pd.merge(checkins_data, clusters_data, on=['user_id'])\n",
    "valuable_users = np.unique(checkins_data.user_id)\n",
    "\n",
    "train_data, test_data = train_test_split(valuable_users, test_size=0.1, shuffle=True)\n",
    "train_checkins = all_data.loc[all_data.user_id.isin(train_data)]\n",
    "test_checkins = all_data.loc[all_data.user_id.isin(test_data)]\n",
    "top_locations = list(train_checkins.groupby(by = 'location_id')['location_id'].count().sort_values(ascending = False).iloc[:10].index)\n",
    "\n",
    "temp = train_checkins.groupby(by = [\"cluster_id\", \"location_id\"])[\"location_id\"].count()\n",
    "train_ratings = temp.reset_index(name='rating').sort_values(by = [\"cluster_id\", \"rating\"], ascending = False)\n",
    "\n",
    "print(\"Сработало\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016974789915966387\n",
      "0.0030812324929971988\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "tp_cluster = 0\n",
    "\n",
    "for i in test_data:\n",
    "    cluster = clusters[i]\n",
    "    locations = test_checkins.loc[test_checkins.user_id == i, \"location_id\"].values\n",
    "    \n",
    "    if (cluster in train_ratings.cluster_id):     \n",
    "        top_cluster = train_ratings.loc[train_ratings.cluster_id == cluster, \"location_id\"].values        \n",
    "        tp_cluster += get_tp(top_cluster, locations, 10)\n",
    "\n",
    "    tp += get_tp(top_locations, locations, 10)\n",
    "\n",
    "precision = tp/(len(test_data)*10)\n",
    "cluster_precision = tp_cluster/(len(test_data)*10)\n",
    "\n",
    "print(precision)\n",
    "print(cluster_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
